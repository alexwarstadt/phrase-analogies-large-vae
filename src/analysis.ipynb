{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd0acda099694ad76001655967d4ca2de79b410be55a02597b12e22a58357e78734",
   "display_name": "Python 3.7.3  ('.mllu': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "acda099694ad76001655967d4ca2de79b410be55a02597b12e22a58357e78734"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install funcy\n",
    "# %env OPTIMUS_CHECKPOINT_DIR=../pretrained_models/optimus_snli10/checkpoint-31250/"
   ]
  },
  {
   "source": [
    "\"\"\"\n",
    "Import our dependencies\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import buckets as b"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading file from scored/plurals_data_scored.csv to /tmp/plurals_data_scored.csv\n",
      "Downloading file from scored/opposite_data_scored.csv to /tmp/opposite_data_scored.csv\n",
      "Downloading file from scored/comparative_data_scored.csv to /tmp/comparative_data_scored.csv\n"
     ]
    }
   ],
   "source": [
    "plurals_filename = b.get_file(\"s3://scored/plurals_data_scored.csv\")\n",
    "opposites_filename = b.get_file(\"s3://scored/opposite_data_scored.csv\")\n",
    "comparatives_filename = b.get_file(\"s3://scored/comparative_data_scored.csv\")\n",
    "plurals = pd.read_csv(plurals_filename)\n",
    "opposites = pd.read_csv(opposites_filename)\n",
    "comparatives = pd.read_csv(comparatives_filename)"
   ]
  },
  {
   "source": [
    "## Plurals"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Counts of each type of value within the plurals dataset\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "plural|from-single                  5007\n",
       "plural|to-some|indefinite            418\n",
       "plural|to-many|indefinite            410\n",
       "plural|to-twenty two|indefinite      408\n",
       "plural|to-ten|indefinite             408\n",
       "plural|to-various|indefinite         379\n",
       "plural|to-one hundred|indefinite     370\n",
       "plural|to-five|indefinite            362\n",
       "plural|to-twenty|indefinite          357\n",
       "plural|to-three|indefinite           335\n",
       "plural|to-six|indefinite             333\n",
       "plural|to-two|indefinite             318\n",
       "plural|to-two hundred|indefinite     300\n",
       "plural|to-nine|indefinite            298\n",
       "plural|to-four|indefinite            292\n",
       "plural|to-twenty|definite              2\n",
       "plural|to-two hundred|definite         2\n",
       "plural|to-six|definite                 1\n",
       "Name: subcategory, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "print(\"Counts of each type of value within the plurals dataset\")\n",
    "plural_type_counts = plurals.subcategory.value_counts()\n",
    "plural_type_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Percentage of each type which were found to be exact matches\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "plural|from-single                   8.168564\n",
       "plural|to-five|indefinite            4.972376\n",
       "plural|to-four|indefinite           11.986301\n",
       "plural|to-many|indefinite            3.658537\n",
       "plural|to-nine|indefinite            0.671141\n",
       "plural|to-one hundred|indefinite     0.000000\n",
       "plural|to-six|definite               0.000000\n",
       "plural|to-six|indefinite             2.702703\n",
       "plural|to-some|indefinite            6.220096\n",
       "plural|to-ten|indefinite             1.470588\n",
       "plural|to-three|indefinite          11.641791\n",
       "plural|to-twenty two|indefinite      0.000000\n",
       "plural|to-twenty|definite            0.000000\n",
       "plural|to-twenty|indefinite          0.560224\n",
       "plural|to-two hundred|definite       0.000000\n",
       "plural|to-two hundred|indefinite     0.000000\n",
       "plural|to-two|indefinite             9.748428\n",
       "plural|to-various|indefinite         0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "print(\"Percentage of each type which were found to be exact matches\")\n",
    "(plurals.groupby(by=\"subcategory\")['score_0_exact'].agg(\"sum\") / plural_type_counts) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Evaluating means of bleu scores\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "subcategory\n",
       "plural|from-single                  0.2526\n",
       "plural|to-five|indefinite           0.2368\n",
       "plural|to-four|indefinite           0.3300\n",
       "plural|to-many|indefinite           0.2407\n",
       "plural|to-nine|indefinite           0.1876\n",
       "plural|to-one hundred|indefinite    0.1206\n",
       "plural|to-six|definite              0.0000\n",
       "plural|to-six|indefinite            0.2214\n",
       "plural|to-some|indefinite           0.2452\n",
       "plural|to-ten|indefinite            0.2042\n",
       "plural|to-three|indefinite          0.3067\n",
       "plural|to-twenty two|indefinite     0.1427\n",
       "plural|to-twenty|definite           0.2789\n",
       "plural|to-twenty|indefinite         0.1731\n",
       "plural|to-two hundred|definite      0.0001\n",
       "plural|to-two hundred|indefinite    0.1645\n",
       "plural|to-two|indefinite            0.3213\n",
       "plural|to-various|indefinite        0.3033\n",
       "Name: score_0_bleu, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "print(\"Evaluating means of bleu scores\")\n",
    "plurals.groupby(by=\"subcategory\")['score_0_bleu'].agg(\"mean\").round(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Median bleu score of each subcategory\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "subcategory\n",
       "plural|from-single                  0.0003\n",
       "plural|to-five|indefinite           0.0002\n",
       "plural|to-four|indefinite           0.2253\n",
       "plural|to-many|indefinite           0.0003\n",
       "plural|to-nine|indefinite           0.0002\n",
       "plural|to-one hundred|indefinite    0.0000\n",
       "plural|to-six|definite              0.0000\n",
       "plural|to-six|indefinite            0.0003\n",
       "plural|to-some|indefinite           0.0003\n",
       "plural|to-ten|indefinite            0.0002\n",
       "plural|to-three|indefinite          0.2115\n",
       "plural|to-twenty two|indefinite     0.0001\n",
       "plural|to-twenty|definite           0.2789\n",
       "plural|to-twenty|indefinite         0.0002\n",
       "plural|to-two hundred|definite      0.0001\n",
       "plural|to-two hundred|indefinite    0.0002\n",
       "plural|to-two|indefinite            0.2605\n",
       "plural|to-various|indefinite        0.0007\n",
       "Name: score_0_bleu, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "print(\"Median bleu score of each subcategory\")\n",
    "plurals.groupby(by=\"subcategory\")['score_0_bleu'].agg(\"median\").round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Opposites"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "opposite|from-possibly       1778\n",
       "opposite|from-decided        1723\n",
       "opposite|from-sure           1697\n",
       "opposite|from-competitive    1358\n",
       "opposite|from-comfortable     551\n",
       "opposite|from-known           527\n",
       "opposite|from-possible        517\n",
       "opposite|from-likely          447\n",
       "opposite|from-certain         369\n",
       "opposite|from-pleasant        328\n",
       "opposite|from-impressive      233\n",
       "opposite|from-aware           225\n",
       "opposite|from-convenient       65\n",
       "opposite|from-responsible      58\n",
       "opposite|from-honest           30\n",
       "opposite|from-fortunate        23\n",
       "opposite|from-reasonable       20\n",
       "opposite|from-productive       14\n",
       "opposite|from-efficient        14\n",
       "opposite|from-informed         13\n",
       "opposite|from-informative      10\n",
       "Name: subcategory, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "opposite_type_counts = opposites.subcategory.value_counts()\n",
    "opposite_type_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "opposite|from-aware          0.444444\n",
       "opposite|from-certain        0.000000\n",
       "opposite|from-comfortable    1.633394\n",
       "opposite|from-competitive    0.000000\n",
       "opposite|from-convenient     0.000000\n",
       "opposite|from-decided        0.000000\n",
       "opposite|from-efficient      0.000000\n",
       "opposite|from-fortunate      0.000000\n",
       "opposite|from-honest         0.000000\n",
       "opposite|from-impressive     0.000000\n",
       "opposite|from-informative    0.000000\n",
       "opposite|from-informed       0.000000\n",
       "opposite|from-known          0.000000\n",
       "opposite|from-likely         0.000000\n",
       "opposite|from-pleasant       0.000000\n",
       "opposite|from-possible       0.000000\n",
       "opposite|from-possibly       0.000000\n",
       "opposite|from-productive     0.000000\n",
       "opposite|from-reasonable     0.000000\n",
       "opposite|from-responsible    0.000000\n",
       "opposite|from-sure           0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "(opposites.groupby(by=\"subcategory\")['score_0_exact'].agg(\"sum\") / opposite_type_counts) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "subcategory\n",
       "opposite|from-aware          0.0757\n",
       "opposite|from-certain        0.1364\n",
       "opposite|from-comfortable    0.1123\n",
       "opposite|from-competitive    0.1540\n",
       "opposite|from-convenient     0.0750\n",
       "opposite|from-decided        0.1091\n",
       "opposite|from-efficient      0.0000\n",
       "opposite|from-fortunate      0.1970\n",
       "opposite|from-honest         0.0000\n",
       "opposite|from-impressive     0.0920\n",
       "opposite|from-informative    0.0002\n",
       "opposite|from-informed       0.0004\n",
       "opposite|from-known          0.0854\n",
       "opposite|from-likely         0.0544\n",
       "opposite|from-pleasant       0.1250\n",
       "opposite|from-possible       0.0685\n",
       "opposite|from-possibly       0.0854\n",
       "opposite|from-productive     0.3119\n",
       "opposite|from-reasonable     0.3020\n",
       "opposite|from-responsible    0.0071\n",
       "opposite|from-sure           0.0398\n",
       "Name: score_0_bleu, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "opposites.groupby(by=\"subcategory\")['score_0_bleu'].agg(\"mean\").round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "subcategory\n",
       "opposite|from-aware          0.0001\n",
       "opposite|from-certain        0.0000\n",
       "opposite|from-comfortable    0.0000\n",
       "opposite|from-competitive    0.0002\n",
       "opposite|from-convenient     0.0002\n",
       "opposite|from-decided        0.0000\n",
       "opposite|from-efficient      0.0000\n",
       "opposite|from-fortunate      0.0004\n",
       "opposite|from-honest         0.0000\n",
       "opposite|from-impressive     0.0000\n",
       "opposite|from-informative    0.0000\n",
       "opposite|from-informed       0.0004\n",
       "opposite|from-known          0.0000\n",
       "opposite|from-likely         0.0000\n",
       "opposite|from-pleasant       0.0003\n",
       "opposite|from-possible       0.0000\n",
       "opposite|from-possibly       0.0000\n",
       "opposite|from-productive     0.4111\n",
       "opposite|from-reasonable     0.3388\n",
       "opposite|from-responsible    0.0000\n",
       "opposite|from-sure           0.0000\n",
       "Name: score_0_bleu, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "opposites.groupby(by=\"subcategory\")['score_0_bleu'].agg(\"median\").round(4)"
   ]
  },
  {
   "source": [
    "## Comparatives\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "comparative|to-comp      5048\n",
       "comparative|from-comp    4952\n",
       "Name: subcategory, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "comparative_type_counts = comparatives.subcategory.value_counts()\n",
    "comparative_type_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "comparative|from-comp    19.487076\n",
       "comparative|to-comp      11.370840\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "(comparatives.groupby(by=\"subcategory\")['score_0_exact'].agg(\"sum\") / comparative_type_counts) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "subcategory\n",
       "comparative|from-comp    0.3256\n",
       "comparative|to-comp      0.3069\n",
       "Name: score_0_bleu, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "comparatives.groupby(by=\"subcategory\")['score_0_bleu'].agg(\"mean\").round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "subcategory\n",
       "comparative|from-comp    0.1593\n",
       "comparative|to-comp      0.1570\n",
       "Name: score_0_bleu, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "comparatives.groupby(by=\"subcategory\")['score_0_bleu'].agg(\"median\").round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}